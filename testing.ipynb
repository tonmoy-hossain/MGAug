{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da710f1-34cc-43cc-91a3-35233bc82dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa562a5-78a6-441c-ae46-f5e6fc275889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from typing import Dict, SupportsRound, Tuple, Any\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch,gc\n",
    "from torch.autograd import grad\n",
    "from torch.autograd import Variable\n",
    "import torch.fft ############### Pytorch >= 1.8.0\n",
    "import torch.nn.functional as F\n",
    "import SimpleITK as sitk\n",
    "import os, glob\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "from PIL import Image\n",
    "import torch.nn.functional as nnf\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts,StepLR\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import random\n",
    "import yaml\n",
    "from tqdm import tqdm, trange\n",
    "from numpy import zeros, newaxis\n",
    "from easydict import EasyDict as edict\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import cv2\n",
    "import lagomorph as lm\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda\"\n",
    "else:\n",
    "    dev = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d6132-578f-4740-a84b-1976e1c7c800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the NumPy array from the pickle file\n",
    "with open('./datasets/mnist_10p_train_x.pkl', 'rb') as file:\n",
    "    final_X_train = pickle.load(file)\n",
    "\n",
    "with open('./datasets/mnist_10p_train_y.pkl', 'rb') as file:\n",
    "    final_y_train = pickle.load(file)\n",
    "\n",
    "with open('./datasets/mnist_10p_test_x.pkl', 'rb') as file:\n",
    "    final_X_test = pickle.load(file)\n",
    "\n",
    "with open('./datasets/mnist_10p_test_y.pkl', 'rb') as file:\n",
    "    final_y_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c382ca0-9422-4513-b746-d5c0e965c1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################Parameter Loading#######################\n",
    "def read_yaml(path):\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            file = edict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "        return file\n",
    "    except:\n",
    "        print('NO FILE READ!')\n",
    "        return None\n",
    "    \n",
    "para = read_yaml('./parameters.yml')\n",
    "\n",
    "xDim = para.data.x \n",
    "yDim = para.data.y\n",
    "zDim = para.data.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1a3fe-3627-4a54-9ed9-38eef114c333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################Network optimization########################\n",
    "\n",
    "'''Check initilization'''\n",
    "from losses import MSE, Grad\n",
    "from network_epdiff import Unet\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "net = Unet(\n",
    "    in_shape = (xDim, yDim),\n",
    "    infeats = 2,\n",
    "    nb_features = [[16, 32, 32], [32, 32, 32, 16, 16]],\n",
    "    nb_levels = None,\n",
    "    max_pool = 2,\n",
    "    feat_mult = 1,\n",
    "    nb_conv_per_level = 1,\n",
    "    half_res = False,\n",
    "    skip_connection = True    \n",
    ")\n",
    "net = net.to(dev)\n",
    "\n",
    "class TDataset(Dataset):\n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.labels[index] if self.labels is not None else None\n",
    "        return data, label\n",
    "\n",
    "\n",
    "train_set = TDataset(final_X_train, final_y_train)\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size = 1, shuffle=True, num_workers=1)\n",
    "\n",
    "test_set = TDataset(final_X_test, final_y_test)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size = para.solver.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "running_loss = 0 \n",
    "running_loss_val = 0\n",
    "template_loss = 0\n",
    "printfreq = 1\n",
    "sigma = 0.02\n",
    "repara_trick = 0.0\n",
    "loss_array = torch.FloatTensor(para.solver.epochs,1).fill_(0)\n",
    "loss_array_val = torch.FloatTensor(para.solver.epochs,1).fill_(0)\n",
    "\n",
    "\n",
    "if(para.model.loss == 'L2'):\n",
    "    criterion = nn.MSELoss()\n",
    "elif (para.model.loss == 'L1'):\n",
    "    criterion = nn.L1Loss()\n",
    "if(para.model.optimizer == 'Adam'):\n",
    "    optimizer = optim.Adam(net.parameters(), lr= para.solver.lr)\n",
    "elif (para.model.optimizer == 'SGD'):\n",
    "    optimizer = optim.SGD(net.parameters(), lr= para.solver.lr, momentum=0.9)\n",
    "if (para.model.scheduler == 'CosAn'):\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=len(trainloader), eta_min=0)\n",
    "\n",
    "optimizer_template = optim.Adam(net.parameters(), lr= para.solver.lr)\n",
    "scheduler_template = CosineAnnealingLR(optimizer_template, T_max=len(trainloader), eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=56, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=56, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)  # Adjusted for input size 128x128\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 64 * 16 * 16)  # Adjusted for input size 128x128\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d09728",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c50a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = 3 # if you want to use any other value, please train and save the augmentation model accordingly and perform testing here. We pre-trained the augmentation model for 3times augmentation here.\n",
    "\n",
    "clf_model_path = './saved_models/mgaug_lddmm_clf_mnist_10p_3t.pth'\n",
    "classifier = torch.load(clf_model_path)\n",
    "classifier.eval()\n",
    "\n",
    "aug_model_path = './saved_models/mgaug_lddmm_mnist_10p.pth'\n",
    "augment = torch.load(aug_model_path)\n",
    "augment.eval()\n",
    "\n",
    "### without test-time augmentation ###\n",
    "print('------------------------------------------')\n",
    "print('Without Test Time Augmentation Performance')\n",
    "print('------------------------------------------')\n",
    "\n",
    "acc = 0\n",
    "predictions = []\n",
    "targets = []\n",
    "with torch.no_grad():\n",
    "    classifier.eval()\n",
    "    augment.eval()\n",
    "    for j, image_data in enumerate(testloader):\n",
    "        inputs, batch_labels = image_data\n",
    "        inputs = inputs.to(dev)\n",
    "        b, c, w, h = inputs.shape\n",
    "\n",
    "        src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "        tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "\n",
    "        outputs = classifier(tar_bch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        labels = [int(label) for label in batch_labels]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.long).to(dev)\n",
    "\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        targets.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "    overall_accuracyw = accuracy_score(targets, predictions)\n",
    "    print(\"Testing Accuracy:\", overall_accuracyw)\n",
    "\n",
    "    precisionw = precision_score(targets, predictions, average='macro')\n",
    "    print(\"Precision:\", precisionw)\n",
    "\n",
    "    recallw = recall_score(targets, predictions, average='macro')\n",
    "    print(\"Recall:\", recallw)\n",
    "\n",
    "    f1w = f1_score(targets, predictions, average='macro')\n",
    "    print(\"F1-score:\", f1w)\n",
    "\n",
    "### with test-time augmentation ###\n",
    "print('------------------------------------------')\n",
    "print('With Test Time Augmentation Performance')\n",
    "print('------------------------------------------')\n",
    "\n",
    "acc = 0\n",
    "predictions = []\n",
    "targets = []\n",
    "with torch.no_grad():\n",
    "    classifier.eval()\n",
    "    augment.eval()\n",
    "    for j, image_data in enumerate(testloader):\n",
    "        inputs, batch_labels = image_data\n",
    "        inputs = inputs.to(dev)\n",
    "        b, c, w, h = inputs.shape\n",
    "\n",
    "        src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "        tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "\n",
    "        outputs = classifier(tar_bch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        labels = [int(label) for label in batch_labels]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.long).to(dev)\n",
    "\n",
    "        correct = (predicted == labels_tensor).sum().item()\n",
    "        accuracy = correct / labels_tensor.size(0) \n",
    "\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        targets.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "    for time in range(times):\n",
    "        for j, image_data in enumerate(testloader):\n",
    "            inputs, batch_labels = image_data\n",
    "            inputs = inputs.to(dev)\n",
    "            b, c, w, h = inputs.shape\n",
    "\n",
    "            src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "            tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "\n",
    "            x = torch.cat([src_bch, tar_bch], dim=1).to(dev)\n",
    "            pred = augment(x)\n",
    "\n",
    "            outputs = classifier(pred[0])\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            labels = [int(label) for label in batch_labels]\n",
    "            labels_tensor = torch.tensor(labels, dtype=torch.long).to(dev)\n",
    "\n",
    "            correct = (predicted == labels_tensor).sum().item()\n",
    "            accuracy = correct / labels_tensor.size(0) \n",
    "\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            targets.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "    overall_accuracy = accuracy_score(targets, predictions)\n",
    "    print(\"Testing Accuracy:\", overall_accuracy)\n",
    "\n",
    "    precision = precision_score(targets, predictions, average='macro')\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    recall = recall_score(targets, predictions, average='macro')\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    f1 = f1_score(targets, predictions, average='macro')\n",
    "    print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = 2 # if you want to use any other value, please train and save the augmentation model accordingly and perform testing here. We pre-trained the augmentation model for 3times augmentation here.\n",
    "\n",
    "clf_model_path = './saved_models/joint_epdiff_mgaug_mnist_clf_10p_2t.pth'\n",
    "classifier = torch.load(clf_model_path)\n",
    "classifier.eval()\n",
    "\n",
    "aug_model_path = './saved_models/joint_epdiff_mgaug_mnist_10p_2t.pth'\n",
    "augment = torch.load(aug_model_path)\n",
    "augment.eval()\n",
    "\n",
    "### without test-time augmentation ###\n",
    "print('------------------------------------------')\n",
    "print('Without Test Time Augmentation Performance')\n",
    "print('------------------------------------------')\n",
    "\n",
    "acc = 0\n",
    "predictions = []\n",
    "targets = []\n",
    "with torch.no_grad():\n",
    "    classifier.eval()\n",
    "    augment.eval()\n",
    "    for j, image_data in enumerate(testloader):\n",
    "        inputs, batch_labels = image_data\n",
    "        inputs = inputs.to(dev)\n",
    "        b, c, w, h = inputs.shape\n",
    "\n",
    "        src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "        tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "\n",
    "        outputs = classifier(tar_bch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        labels = [int(label) for label in batch_labels]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.long).to(dev)\n",
    "\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        targets.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "    overall_accuracyw = accuracy_score(targets, predictions)\n",
    "    print(\"Testing Accuracy:\", overall_accuracyw)\n",
    "\n",
    "    precisionw = precision_score(targets, predictions, average='macro')\n",
    "    print(\"Precision:\", precisionw)\n",
    "\n",
    "    recallw = recall_score(targets, predictions, average='macro')\n",
    "    print(\"Recall:\", recallw)\n",
    "\n",
    "    f1w = f1_score(targets, predictions, average='macro')\n",
    "    print(\"F1-score:\", f1w)\n",
    "\n",
    "### with test-time augmentation ###\n",
    "print('------------------------------------------')\n",
    "print('With Test Time Augmentation Performance')\n",
    "print('------------------------------------------')\n",
    "\n",
    "acc = 0\n",
    "predictions = []\n",
    "targets = []\n",
    "with torch.no_grad():\n",
    "    classifier.eval()\n",
    "    augment.eval()\n",
    "    for j, image_data in enumerate(testloader):\n",
    "        inputs, batch_labels = image_data\n",
    "        inputs = inputs.to(dev)\n",
    "        b, c, w, h = inputs.shape\n",
    "\n",
    "        src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "        tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "\n",
    "        outputs = classifier(tar_bch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        labels = [int(label) for label in batch_labels]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.long).to(dev)\n",
    "\n",
    "        correct = (predicted == labels_tensor).sum().item()\n",
    "        accuracy = correct / labels_tensor.size(0) \n",
    "\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        targets.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "    for time in range(times):\n",
    "        for j, image_data in enumerate(testloader):\n",
    "            inputs, batch_labels = image_data\n",
    "            inputs = inputs.to(dev)\n",
    "            b, c, w, h = inputs.shape\n",
    "\n",
    "            src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "            tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "\n",
    "            x = torch.cat([src_bch, tar_bch], dim=1).to(dev)\n",
    "            pred = augment(x)\n",
    "\n",
    "            outputs = classifier(pred[0])\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            labels = [int(label) for label in batch_labels]\n",
    "            labels_tensor = torch.tensor(labels, dtype=torch.long).to(dev)\n",
    "\n",
    "            correct = (predicted == labels_tensor).sum().item()\n",
    "            accuracy = correct / labels_tensor.size(0) \n",
    "\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            targets.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "    overall_accuracy = accuracy_score(targets, predictions)\n",
    "    print(\"Testing Accuracy:\", overall_accuracy)\n",
    "\n",
    "    precision = precision_score(targets, predictions, average='macro')\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    recall = recall_score(targets, predictions, average='macro')\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    f1 = f1_score(targets, predictions, average='macro')\n",
    "    print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4f966-7bc4-4430-bc59-9aff3c1be307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detJac(np_displacement_field):\n",
    "    \n",
    "    np_displacement_field = np_displacement_field.permute(2, 3, 1, 0).squeeze()\n",
    "    sitk_displacement_field = sitk.GetImageFromArray(np_displacement_field, isVector=True)\n",
    "    jacobian_det_volume = sitk.DisplacementFieldJacobianDeterminant(sitk_displacement_field)\n",
    "    jacobian_det_np_arr = sitk.GetArrayViewFromImage(jacobian_det_volume)\n",
    "    \n",
    "    return jacobian_det_np_arr\n",
    "\n",
    "def save_img(src, tar, deform, field, count):\n",
    "    \n",
    "    src = src.squeeze().detach().cpu()\n",
    "    tar = tar.squeeze().detach().cpu()\n",
    "    deform = deform.squeeze().detach().cpu()\n",
    "    field = field.detach().cpu()\n",
    "    \n",
    "    np_displacement_field = field.permute(2, 3, 1, 0).squeeze()\n",
    "    sitk_displacement_field = sitk.GetImageFromArray(np_displacement_field, isVector=True)\n",
    "    jacobian_det_volume = sitk.DisplacementFieldJacobianDeterminant(sitk_displacement_field)\n",
    "    jacobian_det_np_arr = sitk.GetArrayViewFromImage(jacobian_det_volume)\n",
    "    \n",
    "    src_img = sitk.GetImageFromArray(src)\n",
    "    tar_img = sitk.GetImageFromArray(tar)\n",
    "    def_img = sitk.GetImageFromArray(deform)\n",
    "    detjac = sitk.GetImageFromArray(jacobian_det_np_arr)\n",
    "    \n",
    "    sitk.WriteImage(src_img, f'./save_img/src/src{count}.nii')\n",
    "    sitk.WriteImage(tar_img, f'./save_img/tar/tar{count}.nii')\n",
    "    sitk.WriteImage(detjac, f'./save_img/detJac/dj{count}.nii')\n",
    "\n",
    "def plot(src, tar, deform, count, augment_no):\n",
    "    \n",
    "    src = src.squeeze().detach().cpu()\n",
    "    tar = tar.squeeze().detach().cpu()\n",
    "    deform = deform.squeeze().detach().cpu()\n",
    "    \n",
    "    # fig, axs = plt.subplots(1, 4, figsize=(8, 2))\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(4, 2), gridspec_kw={'width_ratios': [1, 1]}) # [1, 1, 1, 1.5]\n",
    "\n",
    "\n",
    "    axs[0].imshow(src, cmap='gray', aspect='auto')\n",
    "    axs[0].axis('tight')\n",
    "    axs[0].axis('off')  \n",
    "    axs[0].set_title('Img')\n",
    "    \n",
    "    # axs[1].imshow(tar, cmap='gray', aspect='auto')\n",
    "    # axs[1].axis('tight')\n",
    "    # axs[1].axis('off')  \n",
    "    # axs[1].set_title('Tar')\n",
    "    \n",
    "    axs[1].imshow(deform, cmap='gray', aspect='auto')\n",
    "    axs[1].axis('tight')\n",
    "    axs[1].axis('off')  \n",
    "    axs[1].set_title('Augmented')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996bd9cc-de76-4f7b-b0ac-e33553ac84e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aug_model_path = './saved_models/joint_epdiff_mgaug_mnist_10p_2t.pth'\n",
    "augment = torch.load(aug_model_path)\n",
    "augment.eval()\n",
    "\n",
    "count = 0\n",
    "times_of_augmentation = 1\n",
    "\n",
    "for aug_no in range(times_of_augmentation): \n",
    "    with torch.no_grad():\n",
    "        aug_model_path.eval()\n",
    "        print(\"Augment Cycle: \", aug_no)\n",
    "        for j, image_data in enumerate(trainloader):\n",
    "            inputs, batch_labels = image_data\n",
    "            inputs = inputs.to(dev)\n",
    "            b, c, w, h = inputs.shape\n",
    "            optimizer.zero_grad()\n",
    "            src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "            tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "            x = torch.cat([src_bch, tar_bch], dim=1).to(dev)\n",
    "            pred = aug_model_path(x)  \n",
    "\n",
    "            plot(src_bch, tar_bch, pred[0], count, times_of_augmentation)\n",
    "            # save_img(src_bch, tar_bch, pred[0], pred[1], count)\n",
    "\n",
    "            count += 1\n",
    "            \n",
    "print(\"Total Augmented Images: \", times_of_augmentation * len(sampleloader)) # assuming batch size of sampleloader is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a240f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgaug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
