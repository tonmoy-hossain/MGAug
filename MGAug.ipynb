{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2cd1b6-69b3-41e0-83a7-a02f7b69fba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29acc1db-7425-431e-b3f8-bcc830f43cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################Import Packages#######################\n",
    "from __future__ import division, print_function\n",
    "from typing import Dict, SupportsRound, Tuple, Any\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch,gc\n",
    "from torch.autograd import grad\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.fft ############### Pytorch >= 1.8.0\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import SimpleITK as sitk\n",
    "import os, glob\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts,StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import random\n",
    "import yaml\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "import json\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from numpy import zeros, newaxis\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "    \n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21763858-5341-474c-b395-8a46bc6391cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################Parameter Loading#######################\n",
    "def read_yaml(path):\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            file = edict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "        return file\n",
    "    except:\n",
    "        print('NO FILE READ!')\n",
    "        return None\n",
    "    \n",
    "para = read_yaml('./parameters.yml')\n",
    "\n",
    "xDim = para.data.x \n",
    "yDim = para.data.y\n",
    "zDim = para.data.z\n",
    "\n",
    "def loss_Reg(y_pred):\n",
    "        ### For 3D reg ###\n",
    "        # dy = torch.abs(y_pred[:, :, 1:, :, :] - y_pred[:, :, :-1, :, :])\n",
    "        # dx = torch.abs(y_pred[:, :, :, 1:, :] - y_pred[:, :, :, :-1, :])\n",
    "        # dz = torch.abs(y_pred[:, :, :, :, 1:] - y_pred[:, :, :, :, :-1])\n",
    "        # dy = dy * dy\n",
    "        # dx = dx * dx\n",
    "        # dz = dz * dz\n",
    "        # d = torch.mean(dx) + torch.mean(dy) + torch.mean(dz)\n",
    "        # grad = d / 3.0\n",
    "\n",
    "        ### For 2D reg ###\n",
    "        dy = torch.abs(y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :])\n",
    "        dx = torch.abs(y_pred[:, :, :, 1:] - y_pred[:, :, :, :-1])\n",
    "        dy = dy * dy\n",
    "        dx = dx * dx\n",
    "        d = torch.mean(dx) + torch.mean(dy) \n",
    "        grad = d / 2.0\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d060104-6824-42ed-93b9-877032e29369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ##################Data Loading##########################\n",
    "# readfilename = './2DShape/data' + '.json'\n",
    "# datapath = './2DShape/'\n",
    "# data = json.load(open(readfilename, 'r'))\n",
    "# outputs = []\n",
    "# keyword = 'train'\n",
    "# # outputs = np.array(outputs)\n",
    "\n",
    "# for i in trange (0,len(data[keyword])):\n",
    "#     filename_src = datapath + data[keyword][i]['source']\n",
    "#     itkimage_src = sitk.ReadImage(filename_src)\n",
    "#     source_scan = sitk.GetArrayFromImage(itkimage_src)\n",
    "#     source_scan = cv2.resize(source_scan, (128, 128))\n",
    "#     source_scan = (source_scan - np.min(source_scan)) / (np.max(source_scan) - np.min(source_scan))\n",
    "    \n",
    "#     filename_tar = datapath + data[keyword][i]['target']\n",
    "#     itkimage_tar = sitk.ReadImage(filename_tar)\n",
    "#     target_scan = sitk.GetArrayFromImage(itkimage_tar)\n",
    "#     target_scan = cv2.resize(target_scan, (128, 128))\n",
    "#     target_scan = (target_scan - np.min(target_scan)) / (np.max(target_scan) - np.min(target_scan))\n",
    "    \n",
    "#     pair = np.concatenate((source_scan[newaxis,:], target_scan[newaxis,:]), axis=0)\n",
    "#     outputs.append(pair)\n",
    "\n",
    "# train = torch.FloatTensor(outputs)\n",
    "# print (train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e63db9-4b0c-4593-a353-f13d4e36eb67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open('./2DShape.pkl', 'wb') as file:\n",
    "#     pickle.dump(train, file)\n",
    "\n",
    "# Load the NumPy array from the pickle file\n",
    "with open('./2DShape.pkl', 'rb') as file:\n",
    "    train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced12f62-20c4-47e1-8317-0f336e5b5f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Check initilization'''\n",
    "#################Network optimization########################\n",
    "from network import DiffeoDense\n",
    "\n",
    "net = []\n",
    "for i in range(3):\n",
    "    temp = DiffeoDense(inshape = (xDim,yDim),\n",
    "\t\t\t\t nb_unet_features= [[16, 32],[ 32, 32, 16, 16]],\n",
    "                 nb_unet_conv_per_level=1,\n",
    "                 int_steps=7,\n",
    "                 int_downsize=2,\n",
    "                 src_feats=1,\n",
    "                 trg_feats=1,\n",
    "                 unet_half_res= True)\n",
    "    net.append(temp)\n",
    "net = net[0].to(dev)\n",
    "\n",
    "class TDataset(Dataset):\n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.labels[index] if self.labels is not None else None\n",
    "        return data, label\n",
    "    \n",
    "train_labels = json.load(open('./2DShape/data.json','r'))\n",
    "train_set = TDataset(train, [d['label'] for d in train_labels['train']])\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size = para.solver.batch_size, shuffle=True, num_workers=1)\n",
    "sampleloader = torch.utils.data.DataLoader(train_set, batch_size = 1, shuffle=True, num_workers=1)\n",
    "\n",
    "running_loss = 0 \n",
    "running_loss_val = 0\n",
    "template_loss = 0\n",
    "printfreq = 1\n",
    "sigma = 0.02\n",
    "repara_trick = 0.0\n",
    "loss_array = torch.FloatTensor(para.solver.epochs,1).fill_(0)\n",
    "loss_array_val = torch.FloatTensor(para.solver.epochs,1).fill_(0)\n",
    "\n",
    "\n",
    "if(para.model.loss == 'L2'):\n",
    "    criterion = nn.MSELoss()\n",
    "elif (para.model.loss == 'L1'):\n",
    "    criterion = nn.L1Loss()\n",
    "if(para.model.optimizer == 'Adam'):\n",
    "    optimizer = optim.Adam(net.parameters(), lr= para.solver.lr)\n",
    "elif (para.model.optimizer == 'SGD'):\n",
    "    optimizer = optim.SGD(net.parameters(), lr= para.solver.lr, momentum=0.9)\n",
    "if (para.model.scheduler == 'CosAn'):\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=len(trainloader), eta_min=0)\n",
    "\n",
    "optimizer_template = optim.Adam(net.parameters(), lr= para.solver.lr)\n",
    "scheduler_template = CosineAnnealingLR(optimizer_template, T_max=len(trainloader), eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f3001-c839-4c8b-be3a-9716f1ae60a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########### Augmentation Training ###########\n",
    "\n",
    "total_loss = []\n",
    "gmvae_total_loss = []\n",
    "\n",
    "for epoch in trange(para.solver.epochs): \n",
    "    total= 0; \n",
    "    gmvae_loss = 0\n",
    "    total_val = 0; \n",
    "    total_template = 0; \n",
    "    mse_loss = 0\n",
    "    reg_loss = 0\n",
    "    latent_f = []\n",
    "    net.train()\n",
    "    all_labels = []\n",
    "    count = 0\n",
    "    \n",
    "    for j, image_data in enumerate(trainloader):\n",
    "        inputs, batch_labels = image_data\n",
    "        inputs = inputs.to(dev)\n",
    "        b, c, w, h = inputs.shape\n",
    "        src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "        tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = net(src_bch, tar_bch, registration = True)     \n",
    "        loss = criterion(pred[0], tar_bch) \n",
    "        loss2 = loss_Reg(pred[1])\n",
    "        # loss_total = loss + para.solver.alpha * loss2 \n",
    "        loss_total = loss + para.solver.alpha * loss2 + para.solver.beta * pred[3]\n",
    "        loss_total.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss_total.item()\n",
    "        total += running_loss\n",
    "        gmvae_loss += pred[3].item()\n",
    "        running_loss = 0.0\n",
    "        count += 1\n",
    "    \n",
    "    total_loss.append(total/count)\n",
    "    gmvae_total_loss.append(gmvae_loss/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914e742-d89d-4b95-a4ce-f3e06905f34b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = './pre_trained_models/MGAug_2DShape_final.pth'\n",
    "torch.save(net, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a5aa6-6959-4ef5-ac47-664f1a46363f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detJac(np_displacement_field):\n",
    "    \n",
    "    np_displacement_field = np_displacement_field.permute(2, 3, 1, 0).squeeze()\n",
    "    sitk_displacement_field = sitk.GetImageFromArray(np_displacement_field, isVector=True)\n",
    "    jacobian_det_volume = sitk.DisplacementFieldJacobianDeterminant(sitk_displacement_field)\n",
    "    jacobian_det_np_arr = sitk.GetArrayViewFromImage(jacobian_det_volume)\n",
    "    \n",
    "    return jacobian_det_np_arr\n",
    "\n",
    "def save_img(src, tar, deform, field, count):\n",
    "    \n",
    "    src = src.squeeze().detach().cpu()\n",
    "    tar = tar.squeeze().detach().cpu()\n",
    "    deform = deform.squeeze().detach().cpu()\n",
    "    field = field.detach().cpu()\n",
    "    \n",
    "    np_displacement_field = field.permute(2, 3, 1, 0).squeeze()\n",
    "    sitk_displacement_field = sitk.GetImageFromArray(np_displacement_field, isVector=True)\n",
    "    jacobian_det_volume = sitk.DisplacementFieldJacobianDeterminant(sitk_displacement_field)\n",
    "    jacobian_det_np_arr = sitk.GetArrayViewFromImage(jacobian_det_volume)\n",
    "    \n",
    "    src_img = sitk.GetImageFromArray(src)\n",
    "    tar_img = sitk.GetImageFromArray(tar)\n",
    "    def_img = sitk.GetImageFromArray(deform)\n",
    "    detjac = sitk.GetImageFromArray(jacobian_det_np_arr)\n",
    "    \n",
    "    sitk.WriteImage(src_img, f'./save_img/src/src{count}.nii')\n",
    "    sitk.WriteImage(tar_img, f'./save_img/tar/tar{count}.nii')\n",
    "    sitk.WriteImage(def_img, f'./save_img/def/def{count}.nii')\n",
    "    sitk.WriteImage(detjac, f'./save_img/detJac/dj{count}.nii')\n",
    "\n",
    "def plot(src, tar, deform, field, count):\n",
    "    \n",
    "    src = src.squeeze().detach().cpu()\n",
    "    tar = tar.squeeze().detach().cpu()\n",
    "    deform = deform.squeeze().detach().cpu()\n",
    "    field = field.detach().cpu()\n",
    "    \n",
    "    np_displacement_field = field.permute(2, 3, 1, 0).squeeze()\n",
    "    sitk_displacement_field = sitk.GetImageFromArray(np_displacement_field, isVector=True)\n",
    "    jacobian_det_volume = sitk.DisplacementFieldJacobianDeterminant(sitk_displacement_field)\n",
    "    jacobian_det_np_arr = sitk.GetArrayViewFromImage(jacobian_det_volume)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 4, figsize=(6, 1.5), gridspec_kw={'width_ratios': [1, 1, 1, 1.5]})\n",
    "\n",
    "\n",
    "    axs[0].imshow(src, cmap='gray', aspect='auto')\n",
    "    axs[0].axis('tight')\n",
    "    axs[0].axis('off')  \n",
    "    # axs[0].set_title('Src')\n",
    "    \n",
    "    axs[1].imshow(tar, cmap='gray', aspect='auto')\n",
    "    axs[1].axis('tight')\n",
    "    axs[1].axis('off')  \n",
    "    # axs[1].set_title('Tar')\n",
    "    \n",
    "    axs[2].imshow(deform, cmap='gray', aspect='auto')\n",
    "    axs[2].axis('tight')\n",
    "    axs[2].axis('off')  \n",
    "    # axs[2].set_title('Deform')\n",
    "    \n",
    "    gs = axs[3].get_gridspec()\n",
    "    image_plot = axs[3].imshow(jacobian_det_np_arr, cmap='YlGnBu', vmin=jacobian_det_np_arr.min(), vmax=jacobian_det_np_arr.max())\n",
    "    axs[3].axis('off')\n",
    "    colorbar = fig.colorbar(image_plot, ax=axs[3])\n",
    "    colorbar.ax.tick_params(labelsize=6)\n",
    "    colorbar.ax.locator_params(nbins=4) \n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76110358-db37-42d3-9982-2dc459e0c96f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = './pre_trained_models/MGAug_2DShape_final.pth'\n",
    "torch.save(net, PATH)\n",
    "net.eval()\n",
    "\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for j, image_data in enumerate(sampleloader):\n",
    "        inputs, batch_labels = image_data\n",
    "        inputs = inputs.to(dev)\n",
    "        b, c, w, h = inputs.shape\n",
    "        src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "        tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "        # print(src_bch.shape, tar_bch.shape)\n",
    "        pred = net(src_bch, tar_bch, registration = True)   \n",
    "        \n",
    "        plot(src_bch, tar_bch, pred[0], pred[1], count)\n",
    "        save_img(src_bch, tar_bch, pred[0], pred[1], count)\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44d773-f895-447b-abb2-03b2209c48ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
