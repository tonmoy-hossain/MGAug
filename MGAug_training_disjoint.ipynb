{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e2cd1b6-69b3-41e0-83a7-a02f7b69fba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 22 09:55:20 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro RTX 6000                Off |   00000000:3D:00.0 Off |                  Off |\n",
      "| 34%   33C    P2             55W /  260W |     502MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Quadro RTX 6000                Off |   00000000:3E:00.0 Off |                  Off |\n",
      "| 33%   23C    P8             10W /  260W |       2MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  Quadro RTX 6000                Off |   00000000:60:00.0 Off |                  Off |\n",
      "| 33%   27C    P8             26W /  260W |       2MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  Quadro RTX 6000                Off |   00000000:61:00.0 Off |                  Off |\n",
      "| 33%   23C    P8              4W /  260W |     312MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  Quadro RTX 6000                Off |   00000000:B1:00.0 Off |                  Off |\n",
      "| 34%   23C    P8             11W /  260W |       2MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  Quadro RTX 6000                Off |   00000000:B2:00.0 Off |                  Off |\n",
      "| 34%   22C    P8             16W /  260W |       2MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  Quadro RTX 6000                Off |   00000000:DA:00.0 Off |                  Off |\n",
      "| 37%   23C    P8             11W /  260W |       2MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   7  Quadro RTX 6000                Off |   00000000:DB:00.0 Off |                  Off |\n",
      "| 34%   22C    P8             15W /  260W |       2MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    796004      C   /u/pwg7jb/.conda/envs/mgaug/bin/python        500MiB |\n",
      "|    3   N/A  N/A    794563      C   ...x8fh/.conda/envs/cardiac/bin/python        310MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29acc1db-7425-431e-b3f8-bcc830f43cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from typing import Dict, SupportsRound, Tuple, Any\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch,gc\n",
    "from torch.autograd import grad\n",
    "from torch.autograd import Variable\n",
    "import torch.fft ############### Pytorch >= 1.8.0\n",
    "import torch.nn.functional as F\n",
    "import SimpleITK as sitk\n",
    "import os, glob\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "from PIL import Image\n",
    "import torch.nn.functional as nnf\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts,StepLR\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import random\n",
    "import yaml\n",
    "from tqdm import tqdm, trange\n",
    "from numpy import zeros, newaxis\n",
    "from easydict import EasyDict as edict\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import cv2\n",
    "import lagomorph as lm\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda\"\n",
    "else:\n",
    "    dev = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21763858-5341-474c-b395-8a46bc6391cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################Parameter Loading#######################\n",
    "def read_yaml(path):\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            file = edict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "        return file\n",
    "    except:\n",
    "        print('NO FILE READ!')\n",
    "        return None\n",
    "    \n",
    "para = read_yaml('./parameters.yml')\n",
    "\n",
    "xDim = para.data.x \n",
    "yDim = para.data.y\n",
    "zDim = para.data.z\n",
    "\n",
    "def loss_Reg(y_pred):\n",
    "        # For 3D reg\n",
    "        # dy = torch.abs(y_pred[:, :, 1:, :, :] - y_pred[:, :, :-1, :, :])\n",
    "        # dx = torch.abs(y_pred[:, :, :, 1:, :] - y_pred[:, :, :, :-1, :])\n",
    "        # dz = torch.abs(y_pred[:, :, :, :, 1:] - y_pred[:, :, :, :, :-1])\n",
    "        # dy = dy * dy\n",
    "        # dx = dx * dx\n",
    "        # dz = dz * dz\n",
    "        # d = torch.mean(dx) + torch.mean(dy) + torch.mean(dz)\n",
    "        # grad = d / 3.0\n",
    "\n",
    "        dy = torch.abs(y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :])\n",
    "        dx = torch.abs(y_pred[:, :, :, 1:] - y_pred[:, :, :, :-1])\n",
    "\n",
    "        dy = dy * dy\n",
    "        dx = dx * dx\n",
    "        d = torch.mean(dx) + torch.mean(dy) \n",
    "        grad = d / 2.0\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30761975-46a0-4222-bd9d-1758cfcc7757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Load the dataset\n",
    "\n",
    "# Load the NumPy array from the pickle file\n",
    "with open('./datasets/mnist_10p_train_x.pkl', 'rb') as file:\n",
    "    final_X_train = pickle.load(file)\n",
    "\n",
    "with open('./datasets/mnist_10p_train_y.pkl', 'rb') as file:\n",
    "    final_y_train = pickle.load(file)\n",
    "\n",
    "with open('./datasets/mnist_10p_test_x.pkl', 'rb') as file:\n",
    "    final_X_test = pickle.load(file)\n",
    "\n",
    "with open('./datasets/mnist_10p_test_y.pkl', 'rb') as file:\n",
    "    final_y_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d060104-6824-42ed-93b9-877032e29369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ##################Training Data Loading##########################\n",
    "# readfilename = './2DShape/train_data' + '.json'\n",
    "# datapath = './2DShape/'\n",
    "# data = json.load(open(readfilename, 'r'))\n",
    "# outputs = []\n",
    "# keyword = 'train'\n",
    "# # outputs = np.array(outputs)\n",
    "\n",
    "# for i in trange (0,len(data[keyword])):\n",
    "#     filename_src = datapath + data[keyword][i]['source']\n",
    "#     itkimage_src = sitk.ReadImage(filename_src)\n",
    "#     source_scan = sitk.GetArrayFromImage(itkimage_src)\n",
    "#     source_scan = cv2.resize(source_scan, (64, 64))\n",
    "#     if source_scan.ndim == 3 and source_scan.shape == (64, 64, 4):\n",
    "#         source_scan = source_scan[:,:,0]\n",
    "    \n",
    "#     filename_tar = datapath + data[keyword][i]['target']\n",
    "#     itkimage_tar = sitk.ReadImage(filename_tar)\n",
    "#     target_scan = sitk.GetArrayFromImage(itkimage_tar)\n",
    "#     target_scan = cv2.resize(target_scan, (64, 64))\n",
    "#     if target_scan.ndim == 3 and target_scan.shape == (64, 64, 4):\n",
    "#         target_scan = target_scan[:,:,0]\n",
    "        \n",
    "#     # print(source_scan.shape, target_scan.shape)\n",
    "    \n",
    "#     # print(i, source_scan.min(), source_scan.max(), target_scan.min(), target_scan.max())\n",
    "    \n",
    "#     source_scan = (source_scan - np.min(source_scan)) / (np.max(source_scan) - np.min(source_scan))\n",
    "#     target_scan = (target_scan - np.min(target_scan)) / (np.max(target_scan) - np.min(target_scan))\n",
    "    \n",
    "#     pair = np.concatenate((source_scan[newaxis,:], target_scan[newaxis,:]), axis=0)\n",
    "#     outputs.append(pair)\n",
    "#     # print(pair.shape)\n",
    "#     # print(i, source_scan.min(), source_scan.max(), target_scan.min(), target_scan.max())\n",
    "\n",
    "# train = torch.FloatTensor(outputs)\n",
    "# print (train.shape)\n",
    "\n",
    "# ##################Testing Data Loading##########################\n",
    "# readfilename = './2DShape/test_data' + '.json'\n",
    "# datapath = './2DShape/'\n",
    "# data = json.load(open(readfilename, 'r'))\n",
    "# outputs = []\n",
    "# keyword = 'test'\n",
    "# # outputs = np.array(outputs)\n",
    "\n",
    "# for i in trange (0,len(data[keyword])):\n",
    "#     filename_src = datapath + data[keyword][i]['source']\n",
    "#     itkimage_src = sitk.ReadImage(filename_src)\n",
    "#     source_scan = sitk.GetArrayFromImage(itkimage_src)\n",
    "#     source_scan = cv2.resize(source_scan, (64, 64))\n",
    "#     if source_scan.ndim == 3 and source_scan.shape == (64, 64, 4):\n",
    "#         source_scan = source_scan[:,:,0]\n",
    "    \n",
    "#     filename_tar = datapath + data[keyword][i]['target']\n",
    "#     itkimage_tar = sitk.ReadImage(filename_tar)\n",
    "#     target_scan = sitk.GetArrayFromImage(itkimage_tar)\n",
    "#     target_scan = cv2.resize(target_scan, (64, 64))\n",
    "#     if target_scan.ndim == 3 and target_scan.shape == (64, 64, 4):\n",
    "#         target_scan = target_scan[:,:,0]\n",
    "        \n",
    "#     # print(source_scan.shape, target_scan.shape)\n",
    "    \n",
    "#     # print(i, source_scan.min(), source_scan.max(), target_scan.min(), target_scan.max())\n",
    "    \n",
    "#     source_scan = (source_scan - np.min(source_scan)) / (np.max(source_scan) - np.min(source_scan))\n",
    "#     target_scan = (target_scan - np.min(target_scan)) / (np.max(target_scan) - np.min(target_scan))\n",
    "    \n",
    "#     pair = np.concatenate((source_scan[newaxis,:], target_scan[newaxis,:]), axis=0)\n",
    "#     outputs.append(pair)\n",
    "#     # print(i, source_scan.min(), source_scan.max(), target_scan.min(), target_scan.max())\n",
    "\n",
    "# test = torch.FloatTensor(outputs)#.unsqueeze(1)\n",
    "# print (test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ced12f62-20c4-47e1-8317-0f336e5b5f11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip connect: False\n"
     ]
    }
   ],
   "source": [
    "#################Network optimization########################\n",
    "\n",
    "'''Check initilization'''\n",
    "from losses import MSE, Grad\n",
    "from network_epdiff import Unet\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "net = Unet(\n",
    "    in_shape = (xDim, yDim),\n",
    "    infeats = 2,\n",
    "    nb_features = [[16, 32, 32], [32, 32, 32, 16, 16]],\n",
    "    nb_levels = None,\n",
    "    max_pool = 2,\n",
    "    feat_mult = 1,\n",
    "    nb_conv_per_level = 1,\n",
    "    half_res = False,\n",
    "    skip_connection = True    \n",
    ")\n",
    "\n",
    "\n",
    "class TDataset(Dataset):\n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.labels[index] if self.labels is not None else None\n",
    "        return data, label\n",
    "\n",
    "\n",
    "\n",
    "train_set = TDataset(final_X_train, final_y_train)\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size = para.solver.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "test_set = TDataset(final_X_test, final_y_test)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size = para.solver.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "running_loss = 0 \n",
    "running_loss_val = 0\n",
    "template_loss = 0\n",
    "printfreq = 1\n",
    "sigma = 0.02\n",
    "repara_trick = 0.0\n",
    "loss_array = torch.FloatTensor(para.solver.epochs,1).fill_(0)\n",
    "loss_array_val = torch.FloatTensor(para.solver.epochs,1).fill_(0)\n",
    "\n",
    "\n",
    "if(para.model.loss == 'L2'):\n",
    "    criterion = nn.MSELoss()\n",
    "elif (para.model.loss == 'L1'):\n",
    "    criterion = nn.L1Loss()\n",
    "if(para.model.optimizer == 'Adam'):\n",
    "    optimizer = optim.Adam(net.parameters(), lr= para.solver.lr)\n",
    "elif (para.model.optimizer == 'SGD'):\n",
    "    optimizer = optim.SGD(net.parameters(), lr= para.solver.lr, momentum=0.9)\n",
    "if (para.model.scheduler == 'CosAn'):\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=len(trainloader), eta_min=0)\n",
    "\n",
    "optimizer_template = optim.Adam(net.parameters(), lr= para.solver.lr)\n",
    "scheduler_template = CosineAnnealingLR(optimizer_template, T_max=len(trainloader), eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f85f3001-c839-4c8b-be3a-9716f1ae60a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/pwg7jb/.conda/envs/mgaug/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss: 1985.5569100379944 mse_loss: 19.551132526248693 reg_loss: 2.309131383222993 kld_loss 28.134521417617798\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/pwg7jb/PhD_Works/MGAug/MGAug_final_code/MGAug_training_disjoint.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Blotus/u/pwg7jb/PhD_Works/MGAug/MGAug_final_code/MGAug_training_disjoint.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m regularization \u001b[39m=\u001b[39m (pred[\u001b[39m2\u001b[39m]\u001b[39m*\u001b[39mpred[\u001b[39m3\u001b[39m])\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m (tar\u001b[39m.\u001b[39mnumel())\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Blotus/u/pwg7jb/PhD_Works/MGAug/MGAug_final_code/MGAug_training_disjoint.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m loss_total \u001b[39m=\u001b[39m recon_loss\u001b[39m/\u001b[39m(sigma\u001b[39m*\u001b[39msigma) \u001b[39m+\u001b[39m \u001b[39m0.01\u001b[39m\u001b[39m*\u001b[39mregularization \u001b[39m+\u001b[39m \u001b[39m0.001\u001b[39m\u001b[39m*\u001b[39mpred[\u001b[39m5\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://tunnel%2Blotus/u/pwg7jb/PhD_Works/MGAug/MGAug_final_code/MGAug_training_disjoint.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m loss_total\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Blotus/u/pwg7jb/PhD_Works/MGAug/MGAug_final_code/MGAug_training_disjoint.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Blotus/u/pwg7jb/PhD_Works/MGAug/MGAug_final_code/MGAug_training_disjoint.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_total\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.conda/envs/mgaug/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/mgaug/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ##################Training###################################\n",
    "########### Only MGAug Training ###########\n",
    "\n",
    "n_actual_epochs = 200\n",
    "total_loss = []\n",
    "sigma = 0.1\n",
    "net = net.to(dev)\n",
    "\n",
    "for epoch in range(n_actual_epochs): #min(para.solver.epochs, n_actual_epochs)\n",
    "    total= 0; \n",
    "    total_val = 0; \n",
    "    total_template = 0; \n",
    "    mse_loss = 0\n",
    "    total = 0\n",
    "    reg_loss = 0\n",
    "    vae_loss = 0\n",
    "    latent_f = []\n",
    "    net.train()\n",
    "    # print('epoch:', epoch)\n",
    "    all_labels = []\n",
    "    for j, image_data in enumerate(trainloader):\n",
    "        inputs, batch_labels = image_data\n",
    "        inputs = inputs.to(dev)\n",
    "        b, c, w, h = inputs.shape\n",
    "        optimizer.zero_grad()\n",
    "        src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "        tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "        x = torch.cat([src_bch, tar_bch], dim=1).to(dev)\n",
    "        pred = net(x) #, registration = True     \n",
    "        # pred = net(src_bch, tar_bch, registration = True) #, registration = True     \n",
    "        # loss = criterion(pred[0], tar_bch) \n",
    "\n",
    "        Sdef = pred[0]\n",
    "        tar = tar_bch\n",
    "        recon_loss = torch.nn.MSELoss()(tar, Sdef)\n",
    "        regularization = (pred[2]*pred[3]).sum() / (tar.numel())\n",
    "        loss_total = recon_loss/(sigma*sigma) + 0.01*regularization + 0.001*pred[5]\n",
    "\n",
    "        loss_total.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        running_loss += loss_total.item()\n",
    "        total += running_loss\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        mse_loss += recon_loss.item()\n",
    "        reg_loss += 0.01*regularization.item()\n",
    "        vae_loss += (0.001*pred[5].item())\n",
    "        \n",
    "    total_loss.append(total)\n",
    "    print ('epoch:', epoch, 'training loss:', total, 'mse_loss:', mse_loss, 'reg_loss:', reg_loss, 'kld_loss', vae_loss, end=\"\\r\") \n",
    "    \n",
    "# torch.save(net, './saved_models/mgaug_lddmm_mnist_10p.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accc82ad-5f11-4c5e-a23e-ac4f901b3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds():\n",
    "    seed = random.randint(1, 100)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # if you're using CUDA\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca48d7e-a9f1-4dda-9053-f6fd196bfe44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=56, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=56, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)  # Adjusted for input size 128x128\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 64 * 16 * 16)  # Adjusted for input size 128x128\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# input_data = torch.randn(10, 1, 64, 64).to(dev)\n",
    "# model = ConvNet(num_classes=10).to(dev)\n",
    "# output = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "070f4e9e-6ff9-4733-937c-9f5a8becf7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  0\n",
      "----------------\n",
      "Epoch:  0\n",
      "----------------\n",
      "epoch: 0 total training loss: 1089.6640175431967\n",
      "------------------------------------------\n",
      "Without Test Time Augmentation Performance\n",
      "------------------------------------------\n",
      "Testing Accuracy: 0.865\n",
      "Precision: 0.8676437975031442\n",
      "Recall: 0.865\n",
      "F1-score: 0.8650986810621498\n",
      "------------------------------------------\n",
      "With Test Time Augmentation Performance\n",
      "------------------------------------------\n",
      "Testing Accuracy: 0.9023125\n",
      "Precision: 0.9047941824996627\n",
      "Recall: 0.9023125000000001\n",
      "F1-score: 0.9023776106607784\n",
      "----------------\n",
      "Epoch:  1\n",
      "----------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/pwg7jb/PhD_Works/MGAug/MGAug_final_code/MGAug_training_disjoint.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Blotus/u/pwg7jb/PhD_Works/MGAug/MGAug_final_code/MGAug_training_disjoint.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m train_loss \u001b[39m=\u001b[39m criterion(output, labels_tensor)\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Blotus/u/pwg7jb/PhD_Works/MGAug/MGAug_final_code/MGAug_training_disjoint.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m clf_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://tunnel%2Blotus/u/pwg7jb/PhD_Works/MGAug/MGAug_final_code/MGAug_training_disjoint.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m train_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Blotus/u/pwg7jb/PhD_Works/MGAug/MGAug_final_code/MGAug_training_disjoint.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m clf_optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Blotus/u/pwg7jb/PhD_Works/MGAug/MGAug_final_code/MGAug_training_disjoint.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m train_loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.conda/envs/mgaug/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/mgaug/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########### Classification Training ########### \n",
    "\n",
    "times = 3\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "input_size = 64*64\n",
    "\n",
    "\n",
    "final_acc = []\n",
    "final_prec = []\n",
    "final_rec = []\n",
    "final_f1 = []\n",
    "\n",
    "finalw_acc = []\n",
    "finalw_prec = []\n",
    "finalw_rec = []\n",
    "finalw_f1 = []\n",
    "tr_loss = []\n",
    "\n",
    "restart = 5\n",
    "\n",
    "for run in range(0,restart,1):\n",
    "    set_random_seeds()\n",
    "    \n",
    "    model = ConvNet(num_classes=num_classes).to(dev)\n",
    "    clf_optimizer = optim.Adam(model.parameters(), lr= 0.00001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    aug_model = torch.load('./saved_models/mgaug_lddmm_mnist_10p.pth') \n",
    "    aug_model.eval()\n",
    "    \n",
    "    print(\"Run: \", run)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print('----------------')\n",
    "        print('Epoch: ', epoch)\n",
    "        print('----------------')\n",
    "\n",
    "        total = 0\n",
    "        acc = 0\n",
    "        model.train()\n",
    "        \n",
    "        ##### train with ground truth images #####\n",
    "        for j, image_data in enumerate(trainloader):\n",
    "            inputs, batch_labels = image_data\n",
    "            inputs = inputs.to(dev)\n",
    "            b, c, w, h = inputs.shape\n",
    "\n",
    "            src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "            tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "\n",
    "            labels = [int(label) for label in batch_labels]\n",
    "            labels_tensor = torch.tensor(labels, dtype=torch.long).to(dev)\n",
    "\n",
    "            output = model(tar_bch)\n",
    "            train_loss = criterion(output, labels_tensor)\n",
    "\n",
    "            clf_optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            clf_optimizer.step()\n",
    "\n",
    "            total += train_loss.item()\n",
    "            \n",
    "        ##### train with augmented images #####\n",
    "        for time in range(times):\n",
    "            for j, image_data in enumerate(trainloader):\n",
    "                inputs, batch_labels = image_data\n",
    "                inputs = inputs.to(dev)\n",
    "                b, c, w, h = inputs.shape\n",
    "\n",
    "                src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "                tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    x = torch.cat([src_bch, tar_bch], dim=1).to(dev)\n",
    "                    pred = aug_model(x)\n",
    "                    # pred = aug_model(src_bch, tar_bch, registration = True) \n",
    "\n",
    "                labels = [int(label) for label in batch_labels]\n",
    "                labels_tensor = torch.tensor(labels, dtype=torch.long).to(dev)\n",
    "\n",
    "                output = model(pred[0])\n",
    "                train_loss = criterion(output, labels_tensor)\n",
    "\n",
    "                clf_optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                clf_optimizer.step()\n",
    "\n",
    "                total += train_loss.item()\n",
    "\n",
    "        tr_loss.append(total)\n",
    "\n",
    "        print ('epoch:', epoch, 'total training loss:', total)#, 'tr accuracy: ')#, acc/(len(trainloader)*times), end=\"\\r\") \n",
    "\n",
    "        ### without test-time augmentation ###\n",
    "        print('------------------------------------------')\n",
    "        print('Without Test Time Augmentation Performance')\n",
    "        print('------------------------------------------')\n",
    "\n",
    "        acc = 0\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            aug_model.eval()\n",
    "            for j, image_data in enumerate(testloader):\n",
    "                inputs, batch_labels = image_data\n",
    "                inputs = inputs.to(dev)\n",
    "\n",
    "                src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "                tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "\n",
    "                outputs = model(tar_bch)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                labels = [int(label) for label in batch_labels]\n",
    "                labels_tensor = torch.tensor(labels, dtype=torch.long).to(dev)\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                targets.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "            overall_accuracyw = accuracy_score(targets, predictions)\n",
    "            print(\"Testing Accuracy:\", overall_accuracyw)\n",
    "\n",
    "            precisionw = precision_score(targets, predictions, average='macro')\n",
    "            print(\"Precision:\", precisionw)\n",
    "\n",
    "            recallw = recall_score(targets, predictions, average='macro')\n",
    "            print(\"Recall:\", recallw)\n",
    "\n",
    "            f1w = f1_score(targets, predictions, average='macro')\n",
    "            print(\"F1-score:\", f1w)\n",
    "\n",
    "        ### with test-time augmentation ###\n",
    "        print('------------------------------------------')\n",
    "        print('With Test Time Augmentation Performance')\n",
    "        print('------------------------------------------')\n",
    "\n",
    "        acc = 0\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            aug_model.eval()\n",
    "            for j, image_data in enumerate(testloader):\n",
    "                inputs, batch_labels = image_data\n",
    "                inputs = inputs.to(dev)\n",
    "\n",
    "                src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "                tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "\n",
    "                outputs = model(tar_bch)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                labels = [int(label) for label in batch_labels]\n",
    "                labels_tensor = torch.tensor(labels, dtype=torch.long).to(dev)\n",
    "\n",
    "                correct = (predicted == labels_tensor).sum().item()\n",
    "                accuracy = correct / labels_tensor.size(0) \n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                targets.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "            for time in range(times):\n",
    "                for j, image_data in enumerate(testloader):\n",
    "                    inputs, batch_labels = image_data\n",
    "                    inputs = inputs.to(dev)\n",
    "\n",
    "                    src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "                    tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "\n",
    "                    x = torch.cat([src_bch, tar_bch], dim=1).to(dev)\n",
    "                    pred = aug_model(x) \n",
    "\n",
    "                    outputs = model(pred[0])\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                    labels = [int(label) for label in batch_labels]\n",
    "                    labels_tensor = torch.tensor(labels, dtype=torch.long).to(dev)\n",
    "\n",
    "                    correct = (predicted == labels_tensor).sum().item()\n",
    "                    accuracy = correct / labels_tensor.size(0) \n",
    "\n",
    "                    predictions.extend(predicted.cpu().numpy())\n",
    "                    targets.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "            overall_accuracy = accuracy_score(targets, predictions)\n",
    "            print(\"Testing Accuracy:\", overall_accuracy)\n",
    "\n",
    "            precision = precision_score(targets, predictions, average='macro')\n",
    "            print(\"Precision:\", precision)\n",
    "\n",
    "            recall = recall_score(targets, predictions, average='macro')\n",
    "            print(\"Recall:\", recall)\n",
    "\n",
    "            f1 = f1_score(targets, predictions, average='macro')\n",
    "            print(\"F1-score:\", f1)\n",
    "           \n",
    "    finalw_acc.append(overall_accuracyw)\n",
    "    finalw_prec.append(precisionw)\n",
    "    finalw_rec.append(recallw)\n",
    "    finalw_f1.append(f1w)\n",
    "        \n",
    "    final_acc.append(overall_accuracy)\n",
    "    final_prec.append(precision)\n",
    "    final_rec.append(recall)\n",
    "    final_f1.append(f1)\n",
    "\n",
    "print(\"Number of images per class: \", num_images_per_digit)\n",
    "print(\"Model: Conv; Restarts: \", restart, \"Times: \", times)\n",
    "print('Acc with test-time aug: ', np.mean(final_acc), np.std(final_acc))\n",
    "print('Acc without test-time aug: ', np.mean(finalw_acc), np.std(finalw_acc))\n",
    "print('------------------------------------------------------')\n",
    "\n",
    "print('Prec with test-time aug: ', np.mean(final_prec), np.std(final_prec))\n",
    "print('Prec without test-time aug: ', np.mean(finalw_prec), np.std(finalw_prec))\n",
    "print('------------------------------------------------------')\n",
    "\n",
    "print('Rec with test-time aug: ', np.mean(final_rec), np.std(final_rec))\n",
    "print('Rec without test-time aug: ', np.mean(finalw_rec), np.std(finalw_rec))\n",
    "print('------------------------------------------------------')\n",
    "\n",
    "print('F1-Sc with test-time aug: ', np.mean(final_f1), np.std(final_f1))\n",
    "print('F1-Sc without test-time aug: ', np.mean(finalw_f1), np.std(finalw_f1))\n",
    "\n",
    "torch.save(model, './saved_models/mgaug_lddmm_clf_mnist_10p_3t.pth')\n",
    "torch.save(aug_model, './saved_models/mgaug_lddmm_mnist_10p.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f32cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgaug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
